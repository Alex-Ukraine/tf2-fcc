{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tenth.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMkwfbRDxVMHjIwCuPqrl3B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex-Ukraine/tf2-fcc/blob/master/tenth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id8oMSUNmqXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uobje5wxm82j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG_1A-qlnavi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBXvyQQHn9L6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17615af8-08ef-44f7-962a-a60d2fe00509"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmO9NjepoTxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e437b3f2-12e6-45c3-f289-b59a34186189"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQsXHFKCpz5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "    return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i3ajyDkqcAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa2d7551-9de4-4f39-8b80-588de3b9db1d"
      },
      "source": [
        "# lets look at how part of our text is encoded\n",
        "print(\"Text: \", text[:13])\n",
        "print(\"Encoded: \", text_to_int(text[:13]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  First Citizen\n",
            "Encoded:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh0lr60uslbR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "424231a9-2a7b-4594-c805-8d77f8e59060"
      },
      "source": [
        "def int_to_text(ints):\n",
        "    try:\n",
        "        ints = ints.numpy()\n",
        "    except:\n",
        "        pass\n",
        "    return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wqmx8uKtcLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100 # length of sequence for a training example\n",
        "examples_per_epochs = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckc0LqrvuOAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGNLDIMeuYbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk): # for the example: hello\n",
        "    input_text = chunk[:-1] # hell\n",
        "    target_text = chunk[1:] # ello\n",
        "    return input_text, target_text # hell, ello\n",
        "\n",
        "dataset = sequence.map(split_input_target) # we use map to applythe above function to every entry"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxLTrCA9vTTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "64674bcc-7c88-4e9f-c7c3-36b735821699"
      },
      "source": [
        "for x, y in dataset.take(2):\n",
        "    print(\"\\n\\nEXAMPLE\\n\")\n",
        "    print(\"INPUT\")\n",
        "    print(int_to_text(x))\n",
        "    print(\"\\nOUTPUT\")\n",
        "    print(int_to_text(y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CptMkKo0x_mJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVypOvPyfYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8e57317c-3f67-481f-9766-14417d0d142f"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                             return_sequences=True,\n",
        "                             stateful=True,\n",
        "                             recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12tlvLVE6SJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "566d31a0-0b0d-4636-dd98-7b1eec1d708b"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kc2A3Kg6y04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c50ef1d-30fa-4b45-974b-9df944be06c1"
      },
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 4.9541723e-03 -1.0022405e-03  1.5850919e-03 ...  1.9426997e-03\n",
            "    2.3741531e-03 -5.0052702e-03]\n",
            "  [ 3.8164728e-03 -9.6819876e-04  9.7900303e-04 ... -5.9615886e-03\n",
            "    2.4710065e-03 -2.0958320e-03]\n",
            "  [-4.0609809e-03 -8.8512944e-04  5.4686912e-03 ... -7.9739336e-03\n",
            "    1.2142274e-03 -4.7166697e-03]\n",
            "  ...\n",
            "  [-1.4881484e-03  6.9137621e-03  5.9468206e-03 ...  6.0877441e-03\n",
            "   -5.7464559e-03 -1.1508878e-02]\n",
            "  [-3.2905736e-03  6.8410570e-03  6.5180073e-03 ...  3.0175792e-03\n",
            "    1.1985451e-03 -7.8533879e-03]\n",
            "  [-8.6078038e-03  5.0928015e-03  9.4198156e-03 ...  3.5288848e-04\n",
            "   -3.8719759e-04 -9.8840632e-03]]\n",
            "\n",
            " [[ 3.9410675e-03  7.9534324e-03  2.7395627e-03 ...  6.3772040e-04\n",
            "   -3.6351061e-03 -9.7288203e-04]\n",
            "  [-3.3701081e-03  5.7613477e-03  6.2526381e-03 ... -3.5000539e-03\n",
            "   -3.1556520e-03 -4.2213071e-03]\n",
            "  [-1.1801691e-02  6.0356050e-03 -2.6416157e-03 ... -3.1260122e-04\n",
            "    1.0641909e-03 -5.4476243e-03]\n",
            "  ...\n",
            "  [ 7.4175959e-03  1.7577818e-02  1.0221340e-02 ...  5.0198101e-03\n",
            "   -3.3580519e-03 -3.8694842e-03]\n",
            "  [ 1.1866827e-02  1.2398055e-02  8.3379038e-03 ...  5.9061013e-03\n",
            "    9.9867396e-04 -8.2545830e-03]\n",
            "  [ 1.0167771e-02  9.2512714e-03  5.2923081e-03 ... -2.3284205e-03\n",
            "    2.0717615e-03 -4.8274528e-03]]\n",
            "\n",
            " [[-8.7448927e-03  2.0579309e-03 -2.9616366e-04 ... -2.3490721e-03\n",
            "    1.7240496e-03 -1.3461900e-03]\n",
            "  [-2.8269258e-03  9.4599733e-03  2.1850474e-03 ... -1.2097287e-03\n",
            "   -2.3679973e-03 -1.8011280e-03]\n",
            "  [ 6.0780509e-04  3.8462635e-03  2.7001367e-03 ...  2.5561149e-05\n",
            "    3.0187308e-03 -4.8779906e-03]\n",
            "  ...\n",
            "  [ 8.0941562e-03  1.1983002e-02  1.0168387e-02 ...  1.6113692e-03\n",
            "    1.0756959e-03 -5.7907673e-03]\n",
            "  [-2.6957914e-03  1.1207658e-02  7.3796939e-03 ...  4.2872103e-03\n",
            "    1.0485516e-03 -6.1406167e-03]\n",
            "  [-4.9147354e-03  1.1589369e-02  1.1866151e-02 ... -3.8824277e-04\n",
            "   -2.0163620e-03 -1.3001695e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 3.9410675e-03  7.9534324e-03  2.7395627e-03 ...  6.3772040e-04\n",
            "   -3.6351061e-03 -9.7288203e-04]\n",
            "  [ 1.1224058e-02  5.5055381e-03  3.1241090e-03 ...  2.1889161e-03\n",
            "   -1.5264092e-03  3.2857556e-03]\n",
            "  [ 9.5003471e-04  3.2463323e-03  6.6131973e-03 ... -2.6412145e-03\n",
            "   -9.6738141e-04 -1.0797016e-03]\n",
            "  ...\n",
            "  [-2.6733717e-03  5.3942367e-04  1.0172664e-02 ... -6.5559926e-03\n",
            "   -7.5889751e-05 -9.3101114e-03]\n",
            "  [ 4.1141845e-03 -7.3262025e-04  9.2657264e-03 ... -1.7121607e-03\n",
            "    2.2273017e-03 -1.2011421e-02]\n",
            "  [ 7.3572551e-03  7.2151157e-03  9.2507610e-03 ... -4.4587068e-08\n",
            "   -2.5244220e-03 -1.0048424e-02]]\n",
            "\n",
            " [[-1.0152910e-02  1.3824326e-03 -7.2172508e-03 ...  2.2404196e-03\n",
            "    2.3600438e-03 -2.4502003e-03]\n",
            "  [-2.9314982e-03  8.9170001e-03 -2.3477031e-03 ...  2.6978382e-03\n",
            "   -3.2840194e-03 -3.6912251e-03]\n",
            "  [-1.0988530e-02  8.3077941e-03 -1.5537152e-03 ...  4.9360287e-03\n",
            "   -2.0207223e-03 -5.0523137e-03]\n",
            "  ...\n",
            "  [ 7.2494717e-03  4.9922690e-03 -7.0116143e-03 ...  1.7722040e-02\n",
            "   -4.3994435e-03 -6.5478631e-03]\n",
            "  [ 8.3300145e-03  1.1981397e-02 -2.1452075e-03 ...  1.3708433e-02\n",
            "   -8.1348866e-03 -7.0978599e-03]\n",
            "  [ 6.8155269e-04  1.1798170e-02  1.8249515e-03 ...  6.8199057e-03\n",
            "   -8.0791367e-03 -1.1234317e-02]]\n",
            "\n",
            " [[ 3.9410675e-03  7.9534324e-03  2.7395627e-03 ...  6.3772040e-04\n",
            "   -3.6351061e-03 -9.7288203e-04]\n",
            "  [ 4.9087261e-03  7.9671852e-03  4.0564714e-03 ...  1.7351594e-03\n",
            "   -2.4615310e-03 -6.1465357e-03]\n",
            "  [ 4.2697839e-03  9.1931298e-03  6.1039627e-03 ...  5.3749196e-03\n",
            "   -6.0868915e-04 -4.2054998e-03]\n",
            "  ...\n",
            "  [ 1.5875862e-03  7.9906378e-03  5.1399819e-03 ...  2.8306514e-03\n",
            "    7.6040905e-04 -1.3705405e-03]\n",
            "  [ 3.8837153e-03  9.4271814e-03  4.3786722e-03 ...  2.0556846e-03\n",
            "    2.0552834e-03  2.6736341e-03]\n",
            "  [-6.4851930e-03  8.0443891e-03 -2.8757043e-03 ...  4.0996866e-03\n",
            "    5.4899165e-03 -2.0740903e-04]]], shape=(64, 100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ird1eyHv66po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e4087562-3da6-4369-b370-09b97a1af7d6"
      },
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 0.00495417 -0.00100224  0.00158509 ...  0.0019427   0.00237415\n",
            "  -0.00500527]\n",
            " [ 0.00381647 -0.0009682   0.000979   ... -0.00596159  0.00247101\n",
            "  -0.00209583]\n",
            " [-0.00406098 -0.00088513  0.00546869 ... -0.00797393  0.00121423\n",
            "  -0.00471667]\n",
            " ...\n",
            " [-0.00148815  0.00691376  0.00594682 ...  0.00608774 -0.00574646\n",
            "  -0.01150888]\n",
            " [-0.00329057  0.00684106  0.00651801 ...  0.00301758  0.00119855\n",
            "  -0.00785339]\n",
            " [-0.0086078   0.0050928   0.00941982 ...  0.00035289 -0.0003872\n",
            "  -0.00988406]], shape=(100, 65), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upTIGEFa7ETn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "96b3b642-811f-4488-b1fb-e6a870b57cd5"
      },
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 0.00495417 -0.00100224  0.00158509  0.00487944 -0.00266748  0.00031202\n",
            " -0.00294612  0.00060726 -0.00178237  0.00650831  0.00168259  0.00251239\n",
            " -0.00065604 -0.00437894 -0.00332212  0.00061358 -0.0022222   0.00124658\n",
            "  0.00099915 -0.0011928   0.00092941 -0.00073848 -0.00148657 -0.00654347\n",
            "  0.00207511 -0.00017395  0.00668215 -0.00337454 -0.00432866 -0.00066134\n",
            "  0.00057479 -0.00353349  0.00066513 -0.00144657  0.00201985 -0.00261644\n",
            " -0.00210377  0.00070904  0.00364265 -0.00233948 -0.00592984  0.0018767\n",
            "  0.00014709  0.00518904 -0.00147786  0.00182355  0.00183402  0.00393316\n",
            "  0.00207234  0.00475033 -0.00060931  0.00194855  0.00468348  0.00272603\n",
            " -0.00311457  0.00136928  0.01004859 -0.00662069 -0.00102763  0.00144665\n",
            " -0.00086631 -0.00443836  0.0019427   0.00237415 -0.00500527], shape=(65,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct_hxJ-b8OxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da41e18f-5b19-4ee7-ee2d-2ae8335eae71"
      },
      "source": [
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!VsqdLG3$$:Ppq:NDlHeX3rMHRPZ,c:fxRe?LGJW$uEUfPmJzIOPqSmuo&N-nT:3!LIzbek!aYeuchwOUkH&Qhi;Ve:JAiRZT;mz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhSXuNlA9ObM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQZPCHB19c46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS9t5z5u-TOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib-BW72J-zni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd47e53b-3c09-4ac1-9c9a-7bf6085163a1"
      },
      "source": [
        "history = model.fit(data, epochs=40, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 2.6202\n",
            "Epoch 2/40\n",
            "172/172 [==============================] - 12s 72ms/step - loss: 1.9012\n",
            "Epoch 3/40\n",
            "172/172 [==============================] - 13s 73ms/step - loss: 1.6456\n",
            "Epoch 4/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.5069\n",
            "Epoch 5/40\n",
            "172/172 [==============================] - 13s 78ms/step - loss: 1.4256\n",
            "Epoch 6/40\n",
            "172/172 [==============================] - 13s 78ms/step - loss: 1.3674\n",
            "Epoch 7/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.3227\n",
            "Epoch 8/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.2826\n",
            "Epoch 9/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.2461\n",
            "Epoch 10/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.2117\n",
            "Epoch 11/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.1776\n",
            "Epoch 12/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.1401\n",
            "Epoch 13/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 1.1031\n",
            "Epoch 14/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.0657\n",
            "Epoch 15/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 1.0256\n",
            "Epoch 16/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.9873\n",
            "Epoch 17/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.9458\n",
            "Epoch 18/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.9061\n",
            "Epoch 19/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.8669\n",
            "Epoch 20/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.8288\n",
            "Epoch 21/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.7935\n",
            "Epoch 22/40\n",
            "172/172 [==============================] - 13s 75ms/step - loss: 0.7575\n",
            "Epoch 23/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.7272\n",
            "Epoch 24/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.6968\n",
            "Epoch 25/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.6712\n",
            "Epoch 26/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.6470\n",
            "Epoch 27/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.6254\n",
            "Epoch 28/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.6041\n",
            "Epoch 29/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5853\n",
            "Epoch 30/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5693\n",
            "Epoch 31/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5541\n",
            "Epoch 32/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5418\n",
            "Epoch 33/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5295\n",
            "Epoch 34/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5175\n",
            "Epoch 35/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.5065\n",
            "Epoch 36/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4991\n",
            "Epoch 37/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4909\n",
            "Epoch 38/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4830\n",
            "Epoch 39/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4760\n",
            "Epoch 40/40\n",
            "172/172 [==============================] - 13s 76ms/step - loss: 0.4708\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}